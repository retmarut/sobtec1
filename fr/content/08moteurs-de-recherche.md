# Moteurs de recherches

## Ouvert n'est pas libre, publié n'est pas public. La « gratuité » en ligne est une arnaque!

***Ippolita***

Plusieurs années se sont écoulées depuis qu'Ippolita a commencé à faire la
distinction entre l'ouverture au « libre marché », prônée par les gourous du
mouvement *open source* et la liberté que le mouvement du logiciel libre
continue à poser comme base de sa vision des mondes numériques. Le logiciel
libre est une question de liberté, pas de prix.  Il y a dix ans, on aurait pu
penser que le problème ne concernait que les *geeks* et autres
*nerds*. Aujourd'hui, il paraît évident qu'il touche tout le monde. Les grands
intermédiaires numériques sont devenu les yeux, les oreilles, ou au moins les
lunettes de tous les usagers de l'Internet, même de ceux qui n'y accèdent
qu'avec leurs mobiles.

Au risque de paraître grossiers, nous voulons insister sur ce point: l'unique
vocation de l'Open Source est de définir les meilleurs moyens de diffuser un
produit d'une manière *open*, c'est-à-dire ouverte, dans une perspective
purement interne à la logique du marché. L'aspect de l'attitude hacker que
l'on aime, à savoir l'approche ludique et le partage entre pairs, a été
contaminé par une logique de travail et d'exploitation du temps dans un but
lucratif, et non de bien-être personnel et collectif.

Le vacarme au sujet des monnaies électroniques distribuées (ou
crypto-monnaies), tels que Bitcoin, ne fait que renforcer cette
affirmation. Au lieu de jouer dans les interstices pour élargir les espaces et
les degrés de libertés et d'autonomie, au lieu de bâtir nos propres réseaux
auto-organisés pour satisfaire nos besoins et nos désirs, on s'enfonce dans de
la soi-disant monnaie, on gaspille de l’énergie et de l'intelligence dans de
très classiques « chaînes de Ponzi » où les premiers gagneront beaucoup sur le
dos de ceux qui les suivent.

Du point de vue de la souveraineté, on est encore dans le sillon de la
délégation technologique de la confiance qui a débuté il y a des siècles: on
n'a (plus?) aucune confiance dans les États, les institutions, le grandes
entreprises, etc. Tant mieux: *Ars longa, vita brevis*: il est bien tard et il
y a beaucoup de choses plus intéressantes à faire. Malheureusement, au lieu de
tisser patiemment des réseaux de confiance affinitaires, on fait confiance aux
Machines [^1], voire de plus en plus aux Mégamachines qui s'occupent de gérer
ce manque de confiance avec leurs algorithmes *open*: il suffit d'y croire. Il
suffit d'avoir foi dans les Données, de tout révéler aux plateformes sociales,
d'avouer nos désirs plus intimes et ceux de nos proches, pour ainsi contribuer
à la construction d'un réseau unique (propriété privée de quelques grandes
entreprises).

Les Gourous du Nouveau Monde 2.0 nous ont bien dressés aux rituels de
confiance. Un Jobs [^2], tout de noir vêtu, tendant un blanc et pur objet du
désir (un iPod par exemple), aurait pu dire autrefois, sur l'autel-scène des
« Apple Keynotes »,: « Prenez [de la technologie brevetée], et mangez-en :
ceci est mon corps livré pour vous tous ». Mais si l'on essaye de faire
attention à la qualité et à la provenance de ce que l'on mange, pourquoi ne
pas réserver la même attention aux outils et pratiques de communications?.

L'analyse de Google comme champion des nouveaux intermédiaires numériques
qu'Ippolita a menée dans l'essai « Le côté obscur de Google » [^3] se
déployait dans la même optique. Loin d'être un simple moteur de recherche, le
géant de Mountain View a affiché dès sa naissance une claire attitude
hégémonique dans sa tentative de plus en plus aboutie « d'organiser toutes les
connaissances du monde ».

Nous voulions montrer comment la logique *open*-ouverte, combinée à la
conception de l'excellence universitaire californienne (de Stanford en
particulier, berceau de l'anarcho-capitalisme), voyait dans la devise
informelle « Don't be evil » [^4], l'excuse pour se laisser corrompre au
service du capitalisme de l'abondance, du turbo-capitalisme illusoire, de la
croissance illimitée (sixième point de la philosophie de Google: « *Il est
possible de gagner de l'argent sans vendre son âme au diable* » [^5]). On
voudrait nous faire croire que plus, plus grand, plus vite (*more, bigger,
faster*) c'est toujours mieux ; qu'être plus connectés nous rend de plus en
plus libres ; que confier à Google nos « intentions de recherche » nous
permettra de ne plus être confrontés à l'effort de choisir, car le bouton
« J'ai de la chance » nous mènera directement à une source dans laquelle nous
pourrons étancher notre soif de savoir... Mais ces promesses s'exaucent de
moins en moins.

Nous avons de plus en plus faim d'info. La soif de nouveauté est devenue
intarissable. La satisfaction est tellement fugace que l'on ne peut s'empêcher
de chercher encore et encore. À cause aussi de sa taille, le roi des moteurs
de recherche est tombé dans l'inutilité dysfonctionnelle et est devenu une
nuisance, voire une source d'addiction. La terminologie d'Ivan Illich fait ici
mouche: à partir du moment où la société industrielle, par souci d'efficacité,
institutionnalise un moyen (outil, mécanisme, organisme) afin d'atteindre un
but, ce moyen tend à croître jusqu'à dépasser un seuil où il devient
dysfonctionnel et nuit au but qu'il est censé servir. Tout comme l'automobile
nuit au transport, l'école nuit à l'éducation et la médecine nuit à la santé,
l'outil industriel Google devient contre-productif et aliène l'être humain et
la société dans son ensemble.

Bien entendu, ce qui vaut pour Google vaut tout aussi bien pour d'autres
*monopoles radicaux* à l'œuvre: Amazon pour la distribution, Facebook pour la
gestion des relations interpersonnelles, etc. De plus chaque service 2.0 a
tendance à développer ses moteurs et outils de recherche internes donnant
l'impression que le monde, dans toute sa complexité, est à portée d'un clic.

Avec les smartphones cette superposition devient encore plus évidente: si l'on
utilise Android, le système d'exploitation *made in Google*, on se retrouve
complètement plongé dans la vision du monde de Google. Tout qu'on peut y
rechercher et trouver passe, par défaut, par eux.

Dans tous les cas on retrouve la même dynamique à l'oeuvre. Son meilleur
apôtre, c'est Facebook et son monde dans lequel tout est publié, partagé,
exposé... Rien toutefois n'y est public, tout est privé. Nous avons de moins
en moins de contrôle sur les données que nous produisons avec nos recherches,
tous les « J'aime », les posts, les tags, les tweets. Loin d'être souverains,
nous ne sommes que les sujets des principes énoncés par la plate-forme à
laquelle nous confions (littéralement: nous faisons confiance) nos
données. Sans vouloir rentrer dans un débat juridique, dans lequel nous ne
serions pas du tout à l'aise [^6], il suffira de
rappeler que personne ne lit vraiment les contrats d'utilisation (TOS, *Terms
Of Service*) que l'on accepte lorsqu’on utilise ces services.  Dans ces mondes
cloisonnés prolifèrent des règlements de plus en plus prescriptifs dont les
principes poussent le politiquement-correct à l'excès [^7].

La multiplication des règles que personne ne connaît va de pair avec la
multiplication de fonctionnalités (*features*) que peu de gens utilisent. De
toute manière, personne ne saurait vraiment dire comment celles ci se mettent
en place « en exclusivité, pour tout le monde », soit par simple ignorance ou
paresse, soit à cause des interdits entrecroisés des NDA (*Non-Disclosures
Agreement*), Brevets, Trademarks, Copyrights.

Le genre de souveraineté qu'Ippolita aime, c'est l'*autonomie*, le fait de
« se fixer ses propres règles ». Si les règles ne sont pas connues,
l'autonomie est impossible. On commence à peine à comprendre comment opère la
*Filter Bubble*: la pratique du profilage en ligne. La « bulle » des
résultats personnalisés nous engloutit dans une zone d'hétéronomie permanente
qui s’élargit constamment, et dans laquelle les choix sont apanage des
Algorithmes Souverains. Bien entendu, il ne s'agit pas d'une contrainte, nous
sommes complètement libres de nourrir la souveraineté algorithmique avec tous
nos mouvements en ligne, et souvent nous accomplissons à la tache avec
enthousiasme. Celle ci représente la promesse de liberté automatisée:
publicités contextuelles, et étude des sentiment des utilisateurs, afin que
chacun reçoive une annonce personnalisée, sur mesure, du produit à acheter
d’un clic et à jeter au plus vite pour pouvoir acheter quelque chose d’autre.
Nous, utilisateurs, sommes donc des consommateurs qu’il faut connaître sur le
bout des doigts afin de prévoir et assouvir nos désirs, afin de satisfaire nos
« vices » avec des objets aussitôt obsolètes. Rappelons que le profilage est
un produit de la criminologie. Suivre sa logique, même à des fins mercantiles,
c'est *se rapporter à l'autre* comme à un criminel.

Sur ce point Google s'est encore montré le premier. Son moteur de recherche se
fonde sur le *Page Ranking*. À l’origine, tout lien entrant sur un site était
considéré comme l’expression d’un vote de préférence ; les résultats étaient
basés sur ceux pour lesquels avait « voté » la « majorité ». Très vite, les
algorithmes ont été modifiés par des filtres contextuels [^8]. A travers les
résultats de l’algorithme global de *top rank* et à partir des données
dérivant du profilage de l’utilisateur (recherches précédentes, historique de
navigation, etc.), une véritable idéologie de la transparence est apparue
[^9]. Et on ne peut la concrétiser qu’en pillant littéralement les individus
et en jetant leur intériorité (ou pour le moins, ce qui en émane à travers la
machine) en pâture dans un système en ligne. Ces contenus accumulés avec des
procédures de *tracking* [^10] sont répartis en sections de plus en plus fines
pour apporter à chaque internaute un service-produit sur mesure, répondant en
temps réel aux préférences qu’il a exprimés.

La question du profilage est devenue d'autant plus d'actualité depuis les
« scandales » de PRISM et compagnie (quelqu'un se rappelle d'Echelon?
[^11]). Une écrasante majorité des utilisateurs des services 2.0, comprenant
les moteurs de recherches, acceptent les paramètres par défaut. Quand des
modifications interviennent [^12], presque tous les utilisateurs conservent le
nouveau paramétrage. Nous appelons cela le pouvoir « par défaut »: la vie en
ligne de millions d’utilisateurs peut être entièrement bouleversée, simplement
en opérant quelques réglages.

Tel est le côté obscur des systèmes de recherches issus du profilage! Il est
ainsi possible qu’un beau jour, en tapant son identifiant et son mot de passe,
on trouve l’organisation de l’espace de son compte personnel totalement
modifiée, un peu comme si en rentrant à la maison, on découvrait que la
décoration a changé et que les meubles ne sont plus à leur place. C’est ce
qu’il faut toujours avoir présent à l’esprit lorsqu'on parle de solutions
technologique pour tout le monde, c'est-à-dire pour la masse: bien que
personne ne veuille en faire partie quand nous utilisons ces outils
commerciaux et gratuits, nous sommes la masse. Et nous nous soumettons au
pouvoir « par défaut »: cela implique que quand on change le défaut, on
affiche notre « diversité », car notre choix de changer est bien enregistré
dans notre profil [^13].

La *Pars Destruens* est bien entendu la plus simple à étaler. Il n'est pas
trop difficile d'articuler des critiques radicales. D'autre part, le simple
fait de sentir la nécessité de trouver des alternatives aux moteurs de
recherches actuellement disponibles ne garantit aucunement d’aboutir à un
résultat satisfaisant. Le cas de la navigation sécurisée, que nous enseignons
lors de nos formations à l’autodéfense numérique, est un bon indice pour
évaluer la qualité de nos recherches et de notre rapport à la toile en
général.

On pourrait remplir de longues pages expliquant l'usage de telle ou telle
extension de Firefox [^14] qui aidera à échapper au flicage, bloquera les
pubs, ou bien interdira aux mineurs d'arriver sur des sites « dangereux »
(selon, notre avis d'adultes-parents-éducateurs souvent biaisé par la
rhétorique réac' de la « toile dangereuse ») . Il est possible d’effacer tous
les cookies et les LSO (*Localised Shared Object*), de se connecter de façon
anonyme avec des VPN (*Virtual Private Networks*), de cryptographier chaque
communication, d’utiliser TOR et d'autres outils encore plus pointus, de façon
à que Google & Co ne sachent plus rien de nous.

Oui, mais... plus j’essaie de me protéger, plus je me distingue de la masse et
plus il est aisé de me reconnaître. Si mon navigateur est bardé d’extensions
destinées à éviter le profilage, à rendre anonyme et à cryptographier, et si
j’utilise uniquement un système d’exploitation bien particulier GNU/Linux pour
accéder à la Toile (quelle saveur?  Ubuntu, Debian, Arch, Gentoo, *from
scratch...* il y aura toujours quelqu’un de plus « pur »!), je suis plus
facile à reconnaître paradoxalement qu’un internaute qui utilise des systèmes
moins sophistiqués et plus communs [^15].

La cryptographie suscite aussi beaucoup de critiques, surtout parce qu’elle
est fondée sur le même principe de croissance illimitée – toujours plus
puissant, toujours plus rapide – que le turbo-capitalisme libertarien. En
augmentant la puissance de calcul et la vitesse des réseaux, on augmente
l’efficacité des systèmes cryptographiques les plus récents ; en même temps,
les vieux verrous deviennent rapidement obsolètes.

Ce mécanisme de croissance-obsolescence entre dans une logique militaire
d’attaque et de défense, d’espionnage et de contre-espionnage.  N’oublions pas
qu’il s’agit toujours à la base de systèmes conçus pour des applications
militaires et qu’ils sont aussi parfois destinés à faire en sorte que les
communications ne soient pas interceptées par le camp ennemi. La
cryptographie, en somme, est une bonne pratique, surtout pour les passionnés
d’informatique qui adorent les casse-tête logiques, mais son approche n’est
pas satisfaisante.

La *Pars Construens* devrait donc commencer par la reconnaissance humble  de
que la technologie n'est ni bonne, ni mauvaise, ni (surtout pas!)
neutre. L'usage des technologies dépend des personnes. En soi, une
technologie, même la meilleure du monde (mais selon quels critères?), ne
garantit strictement rien. L'approche méthodologique que nous aimons suggèrer
est celle d 'évaluer, non pas le « quoi » (quelles alternatives aux moteurs de
recherches?) mais le « comment »: la façon dont les instruments technologiques
se créent et se modifient à travers leurs utilisation, les méthodes avec
lesquelles les individus et les groupes s'adaptent et changent leurs propres
comportements.

Deuxième admission d'humilité: les questions sociales sont avant tout des
questions humaines, de relations entre les êtres humains, chacun dans son
propre environnement. Malgré la haute résolution des écrans tactiles, malgré
la vitesse instantanée des milliards de résultats des presque omnipotents
moteurs de recherche, la civilisation 2.0 est très semblable aux civilisations
qui l’ont précédée, parce que les êtres humains continuent de chercher à
attirer l’attention de leurs semblables. Ils ont toujours besoin de se
nourrir, de dormir, d’entretenir des relations amicales, de donner un sens au
monde auquel ils appartiennent. Ils tombent encore amoureux et ont des
déconvenues, ils rêvent et espèrent, se trompent, se pillent, se font du mal,
se tuent.

En un mot, les êtres humains doivent être conscients de la finitude de leur
existence dans le temps (l’incompréhensibilité de la mort) et dans l’espace
(le scandale de l’existence des autres, d’un monde extérieur), même à l’ère
des moteurs de recherches ciblés et des réseaux sociaux numériques.

Comment ces considérations peuvent-elles nous aider à mieux chercher, c'est à
dire à chercher « différemment »?

L'hégemonie des moteurs de recherche géants repose sur une accumulation de
données sans limite: il devient évident que c'est une question de
taille. *Size matters*! La taille importe! Une information et une recherche
conviviale qui encourage la réalisation de la liberté individuelle au sein
d’une société dotée d’outils efficaces reste possible. De fait la conclusion
logique d'une critique de l’informatique de la domination réside dans le
revers du « small is beautiful ».

Les dimensions jouent un rôle considérable. Au-delà d’une certaine échelle,
une hiérarchie fixe est nécessaire pour gérer les rapports entre les êtres
humains et entre tous les **êtres** en général, vivants ou non. Entre les
machines et protocoles, les câbles, membranes, et procédures de stockage et de
recherche. Mais qui contrôlera les intermédiaires? Si l'on fait confiance à
des outils-intermédiaires trop grands pour nos recherches, il faut accepter la
mise en place d'une hiérarchie de domination. Tout est relatif, tout est « en
relation avec ».

Les connaissances emmagasinées dans ce qu’on appelle le « Big data » [^16],
sont une chimère parce que les connaissances profitables aux êtres humains ne
sont pas à l’extérieur et ne sont pas interchangeables ; si elles peuvent être
objectivées, échangées, apprises, traduites et partagées, les connaissances
sont avant tout un processus individuel d’imagination.  Contrairement à la
mémoire totale irréfléchie des instruments numériques, l’identification, le
devenir soi-même est un processus au cours duquel nous perdons continuellement
connaissance, nous perdons la mémoire et nous la reconstruisons, comme nous
nous reconstruisons dans nos processus vitaux. Si au lieu d’avoir un nombre
limités de sources, dans lesquelles nous sélectionnons nos parcours, nous
créons notre propre histoire que nous racontons et partageons, nous décidons
de puiser dans une quantité illimité de données d'une façon automatisée par
des systèmes de profilage, la relativité cède le pas à l’homologation.  On
nourrit ainsi les Mégamachines.

Ces dernières impliquent des relations de cause à effet de type capitaliste ou
despotique. Elles génèrent dépendance, exploitation, impuissance des êtres
humains réduits à n’être que des acheteurs asservis. Et que cela soit dit
encore une fois pour les partisans des *commons, ce n’est pas une question de
propriété, parce que*:

> la propriété collective des moyens de production ne change rien à cet état
> de choses et nourrit seulement une organisation despotique
> stalinienne. Aussi Illich lui oppose-t-il le droit pour chacun d’utiliser
> les moyens de production, dans une « société conviviale », c’est-à-dire
> désirante et non œdipienne. Ce qui veut dire: l’utilisation la plus
> extensive des machines par le plus grand nombre possible de gens, la
> multiplication de petites machines et l’adaptation des grandes machines à de
> petites unités, la vente exclusive d’éléments machiniques qui doivent être
> assemblés par les usagers-producteurs eux-mêmes, la destruction de la
> spécialisation du savoir et du monopole professionnel [^17].

La question qui se re-pose encore et toujours est donc: comment faire?  Quels
désirs avons-nous à l'égard des technologies de recherche?  Veut-on *trouver*
immédiatement, ou bien voudrait-on aussi parcourir un chemin? Peut-être
veut-on se perdre avec des copains, ou toute seule ; peut-être s'immerger dans
des profondeurs inconnues et pas facilement *partageables* avec un clic, un
tag, un post.

Des moteurs de recherche « en situation », qui assument une perspective pas du
tout « objective », mais explicitement « subjective », en expliquant le
pourquoi et le comment. La multiplication des petits moteurs de recherches,
voilà une possibilité souvent peu explorée! Un critère possible quant à leur
évaluation pourrait alors être leur capacité de s’adresser à un groupe
particulier avec des exigences particulières. Cette aspiration minoritaire
impliquerait logiquement la volonté de répondre non pas d'une façon
quasi-instantanée aux requêtes de tout le monde, c'est-à-dire d'une masse
soumise au profilage, mais de se borner à creuser les limites d'une
connaissance toujours inachevée.  Cela conjurerait la mise en place des
prétentions totalitaires, ce bien connu côté obscur des Lumières et de tous
les projets de connaissance globale.

Le recours à l'expertise des composants de notre « réseau social », et pas
seulement en ligne, reprèsente une autre possibilité incroyablement efficace
si le but est celui de se créer une référence fiable sur un sujet
particulier. Il s'agirait alors de choisir attentivement à qui « faire
confiance ».

L'adoption d'un style sobre est peut-être l'alternative la plus puissante pour
contrer la prolifération de solutions technologiques que nous n'avons jamais
demandé mais auxquelles nous avons tant de mal à nous soustraire. En effet,
l'imposition de l'obsolescence programmé s'applique aussi au domaine de la
recherche, en commençant par l’équivalence « à majeure quantité plus de
qualité », fruit d'une aveugle application de l’idéologie du progrès à tout
prix . Avoir un grand nombre d'objets, dans le monde 2.0, signifie aussi avoir
accès à un nombre de résultats en croissance infinie et exponentielle, de plus
en plus taillés sur nos préférences plus ou moins explicitement
affichées. Suivant la même logique, la durabilité d'un résultat devrait aussi
être prise en compte: une foulée de résultats valables pour peu de jours,
heures voire minutes devraient avoir moins d’intérêt par rapport à des
résultats plus solides face au temps qui passe.

S’échapper de l'economicisme religieux de la consommation obligée signifierait
donc mettre en place une sorte de décroissance, dans la recherche en ligne,
comme dans tout autre domaine technologique. Ces processus d'auto-limitation
et de choix attentifs ne pourront aucunement être « heureux » dans le sens de
dépourvus d'effort ou quasiment automatisés. Aucune addiction, et encore moins
l'addiction à une technologie « gratuite » de la réponse immédiate, peut être
interrompue sans conséquences. En d'autre mots, si notre désir se centre sur
un moteur « libre » qui soit à 99,99 % aussi rapide, puissant et disponible
que Google, alors la seule possibilité sera de mettre en place un autre Moloch
comme celui de Mountain View.

À ceux qui éventuellement voudraient sentir le sacrifice dans cette tension
qu'on pourrait nommer écologiste, on répondra sur le ton de l’allégorie et
reviendrons au thème de la nourriture : pourquoi s'engouffrer n'importe quelle
saleté industrielle au lieu de bien choisir les ingrédients de ses repas?
Pourquoi se gaver de résultats quand on pourrait développer notre propre
goût? La vie est trop brève pour boire du mauvais vin en quantité!

Il y a beaucoup d’expérimentations autogérées déjà actives, il suffit d'ouvrir
grand les yeux, de sentir l'air autour de soi, de tendre ses oreilles, de
toucher, de mettre la main à la pâte et de goûter en entraînant son goût aux
bonnes choses: bref, il suffit de se mettre à leur recherche. S'attendre à ce
que les autres le fassent à notre place est une drôle d'idée, autant croire
que les Grands Moteurs de Recherche nous fournissent immédiatement et
gratuitement et sans aucun effort la réponse correcte. Il n'y a aucun oracle
omniscient, seulement des personnes auxquelles on décide de se confier.

------------------------------------------------------------------------

**Ippolita:** Groupe de recherche interdisciplinaire qui creuse les
«technologies de la domination» et leurs effets sociaux en pratiquant les
écritures conviviales. Parmi ses essais copyleft: "Open n'est pas
Libre. Communautés numériques entre éthique hackers et marché global"
(Elèuthera, 2005), "The Dark Side Of Google" (Feltrinelli, 2007, traduit en
français, castillan et anglais), "Dans l'aquarium de Facebook. La irrésistible
ascension de l'anarcho-capitalisme" (Ledizioni, Milan, 2012, traduit en
français, castillan, anglais), "La Toile est libre et démocratique. FAUX!" (en
cours de publication). Ippolita propose des formations d'auto-défense
numérique et de validation des sources. http://ippolita.net

------------------------------------------------------------------------

[^1]: Voir Giles Slade, *The Big Disconnect: The Story of Technology and Loneliness*, Prometheus Books, NY, 2012, en particulier le troisième chapitre, «Trusting Machines».

[^2]: Par exemple, https://upload.wikimedia.org/wikipedia/commons/b/b9/Steve_Jobs_Headshot_2010-CROP.jpg

[^3]: Ippolita, *Le* *côté* *obscur* *de Google*, Payot&Rivages, Paris, 2011 (2008); ed. or. it. *Luci e Ombre di Google,* Feltrinelli, Milano, 2007. Free copyleft download: http://ippolita.net

[^4]: Ne sois pas malveillant / Ne fais pas le mal.

[^5]: Dix repères clés: http://www.google.com/intl/fr/about/company/philosophy/

[^6]: Surtout parce que le droit implique des lois et des juges qui sanctionnent leurs contrevenants d'autant plus facilement qu'ils ne peuvent pas se payer de bons avocats. Voir Carlo Milani, « Topologies du devenir libertaire. II – Droits? », dans *Philosophie de l'anarchie. Théories libertaires, pratiques quotidiennes et ontologie*, ACL, Lyon, 2012, pp. 381-384.

[^7]: Si Google fait de la Philosophie, Facebook affiche des Principes https://www.facebook.com/principles.php.

[^8]: Voir Ippolita, *Le côté obscur de Google*, cit., « V. En prime, d'autres fonctions ingénieuses », pp.  153-178.

[^9]: Les travaux de Danah Boyd donnent sur la question un point de vue très clair, son site http://www.zephoria.org/ mérite une visite. Pour un perspective plus philosophique, voir Byung-Chul Han, *Transparenzgesellschaft*, Matthes & Seitz, Berlin, 2012.

[^10]: Le site http://donttrack.us/ expose très clairement, en une brève présentation, le système de traçage des recherches. Il nous donne aussi l'occasion de faire une première allusion aux « alternatives », DuckDuckGo en étant une. Un moteur de recherche qui affirme de ne pas faire du *tracking*. Le scepticisme méthodologique que nous prônons nous impose de faire remarquer que c'est bien possible: il faut juste faire confiance à DuckDuckGo...

[^11]: Et pourtant, on sait bien depuis la publication en 1999 du report européen de Duncan Campbell *Interception Capabilities* que l'espionnage numérique se fait à l’échelle globale: http://www.cyber-rights.org/interception/stoa/interception_capabilities_2000.htm

[^12]: Comme cela a été le cas plusieurs fois en 2012 et 2013, lorsque Google a redéfini ses paramètres de confidentialité et d'entrecroisement-partage des données entre ses différents services.

[^13]: Vous pouvez facilement le vérifier: demandez à vos amis et collègues s'ils ont changé les paramétrage par défaut de Google. Normalement (au début de l'année 2014) le *Safe Search filter* que Google met en place pour vous éviter de tomber sur des résultats « illicites » est réglé sur la « moyenne », à savoir il filtre le contenu à caractère sexuel explicite dans vos résultats de recherche. Il devient de plus en plus compliqué de détecter ce genre de paramétrage. La raison est bien expliquée par une source explicitement *corporate*: la stratégie de *business* optimale pour les géants du profilage en ligne est d'offrir des systèmes de réglage de la confidentialité difficiles à utiliser. Voir « Appendix: a game theoretic analysis of Facebook privacy settings », dans Robert H. Sloan, Richard Warner, *Unauthorized access. The Crisis in Online Privacy and Security*, CRC Press, 2014, pp. 344-349.

[^14]: Voir par exemple Manuel Security in a box: https://securityinabox.org/fr/firefox_principale

[^15]: Un panorama en a été esquissé dans Ippolita, *J'aime pas Facebook,* Payot&Rivages, 2012, *Troisième Partie. Les libertés du réseau*, « Réactions et anthropotechniques de survie », pp. 235-250. Voir aussi projet Panopticlick de la EFF et Ixquick: https://panopticlick.eff.org/ • https://www.ixquick.com/eng/

[^16]: Voir https://fr.wikipedia.org/wiki/Big_data

[^17]: Gilles Deleuze, Félix Guattari, « Appendice, Bilan-programme pour machines désirantes », *L’Anti-Œdipe*, Éditions de Minuit, Paris, 1975, p. 479.
